{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'add'\n",
    "(input_train, input_dev, input_test, \n",
    "           target_train, target_dev, target_test) = utils.import_data(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the training dataset takes all examples, then the dev and test datasets are the same as the training one. \n",
    "if input_dev.shape[0] == 0:\n",
    "    input_dev = input_train\n",
    "    target_dev = target_train\n",
    "    input_test = input_train\n",
    "    target_test = target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 16)\n",
      "(65536, 16)\n",
      "(65536, 16)\n",
      "(65536, 9)\n",
      "(65536, 9)\n",
      "(65536, 9)\n"
     ]
    }
   ],
   "source": [
    "print(input_train.shape)\n",
    "print(input_dev.shape)\n",
    "print(input_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_dev.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Break down the training set with the defined batch size.\n",
    "2. Give away the last batch if it does not have the batch size.\n",
    "3. Start a new epoch.\n",
    "4. Shuffle the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_saved_models = 'saved_models'\n",
    "rootdir_logs = 'tf_logs'\n",
    "train_print_period = 100\n",
    "dev_print_period = 1000\n",
    "\n",
    "# Contants\n",
    "INPUT_DIM = input_train.shape[1] \n",
    "OUTPUT_DIM = target_train.shape[1]\n",
    "\n",
    "# Hyperparameters - training\n",
    "batch_size = 32\n",
    "n_epoch = 999999999999\n",
    "str_optimizer = 'adam'\n",
    "learning_rate = 0.001\n",
    "all_correct_stop = False\n",
    "full_batch_saturation = True\n",
    "if full_batch_saturation:\n",
    "    all_correct_stop = False\n",
    "\n",
    "# Hyperparameters - model\n",
    "nn_model_type = 'mlp' # mlp, cnn, rnn\n",
    "activation = tf.nn.sigmoid\n",
    "h_layer_dims = [32] # h_layer_dims[0]: dim of h1 layer\n",
    "last_size = OUTPUT_DIM\n",
    "\n",
    "# Variables determined by other variables\n",
    "train_size = input_train.shape[0]\n",
    "n_batch = train_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bit_input_number = INPUT_DIM // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define a computational graph for the feedforward neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=(None, input_train.shape[1]), name='inputs') # None for mini-batch size\n",
    "targets = tf.placeholder(tf.float32, shape=(None, target_train.shape[1]), name='targets')\n",
    "\n",
    "training_epoch = tf.placeholder(tf.float32, shape=None, name='training_epoch') \n",
    "full_batch_training = tf.placeholder(tf.int8, shape=None)\n",
    "\n",
    "# Weight initialization\n",
    "if activation == tf.nn.relu:\n",
    "    kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0)\n",
    "if activation == tf.nn.sigmoid:\n",
    "    kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=1.0)\n",
    "if activation == tf.nn.tanh:\n",
    "    kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=1.0)\n",
    "    \n",
    "# NN structure\n",
    "h1 = tf.layers.dense(inputs, h_layer_dims[0], activation=activation, kernel_initializer=kernel_initializer, name='h1')\n",
    "last_logits = tf.layers.dense(h1, last_size, activation=None, kernel_initializer=kernel_initializer, name='last_logits')\n",
    "sigmoid_outputs = tf.sigmoid(last_logits)\n",
    "predictions = utils.tf_tlu(sigmoid_outputs)\n",
    "\n",
    "# Loss: objective function\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=last_logits) # https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy\n",
    "(accuracy, n_wrong, n_correct) = utils.get_measures(targets, predictions)\n",
    "\n",
    "# Training, optimization\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyzing activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.1. Restore a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_saved_model = 'saved_models'\n",
    "model_id = '20181001180511'\n",
    "model_to_import = '{}/{}/{}/epoch2000-batch2047.ckpt'.format(\n",
    "    operator, nn_model_type, model_id)\n",
    "\n",
    "#saver = tf.train.import_meta_graph('{}/{}.meta'.format(dir_saved_model, model_to_import))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Visualizing the activations in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_models/add/mlp/20181001180511/epoch2000-batch2047.ckpt\n",
      "Model restored.\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1.2672061e-07 6.3365526e-02 6.5915170e-03 1.0000000e+00 9.9999857e-01\n",
      "  1.0000000e+00 8.5556477e-01 9.9995208e-01 7.7304427e-11 1.0000000e+00\n",
      "  5.1879689e-17 1.0000000e+00 1.0000000e+00 8.6415701e-02 8.1727666e-01\n",
      "  5.9810996e-01 1.0000000e+00 1.0000000e+00 1.0000000e+00 3.4562549e-07\n",
      "  2.0407976e-15 1.8534452e-01 8.9284098e-01 1.0000000e+00 6.1623180e-01\n",
      "  2.5491493e-06 1.0000000e+00 3.3567307e-16 1.0000000e+00 1.0000000e+00\n",
      "  9.9996150e-01 3.4538275e-01]]\n",
      "[1.2672061e-07 6.3365526e-02 6.5915170e-03 1.0000000e+00 9.9999857e-01\n",
      " 1.0000000e+00 8.5556477e-01 9.9995208e-01 7.7304427e-11 1.0000000e+00\n",
      " 5.1879689e-17 1.0000000e+00 1.0000000e+00 8.6415701e-02 8.1727666e-01\n",
      " 5.9810996e-01 1.0000000e+00 1.0000000e+00 1.0000000e+00 3.4562549e-07\n",
      " 2.0407976e-15 1.8534452e-01 8.9284098e-01 1.0000000e+00 6.1623180e-01\n",
      " 2.5491493e-06 1.0000000e+00 3.3567307e-16 1.0000000e+00 1.0000000e+00\n",
      " 9.9996150e-01 3.4538275e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, '{}/{}'.format(dir_saved_model, model_to_import))\n",
    "    print(\"Model restored.\")\n",
    "        \n",
    "    n1 = np.asarray([[0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float)\n",
    "    n2 = np.asarray([[0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float)\n",
    "    input_test = np.concatenate((n1, n2), axis=1)\n",
    "    \n",
    "    [predictions_value, h1_value] = sess.run(\n",
    "        [predictions, h1],\n",
    "        feed_dict={inputs:input_test})\n",
    "    print(predictions_value)\n",
    "    print(h1_value)\n",
    "    print(np.squeeze(h1_value))\n",
    "    \n",
    "    \n",
    "    x = list(range(h1_value.shape[1]))\n",
    "    y = np.squeeze(h1_value)\n",
    "    yticks = [0.05 * i for i in range(21)]\n",
    "    plt.bar(x, y)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(x)\n",
    "    plt.yticks(yticks)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Computing the layers and get and save their values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_models/add/mlp/20181001180511/epoch2000-batch2047.ckpt\n",
      "Model restored.\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, '{}/{}'.format(dir_saved_model, model_to_import))\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    layers = list()\n",
    "    for i1 in range(2**n_bit_input_number):\n",
    "        for i2 in range(2**n_bit_input_number):\n",
    "            result_dict = dict()\n",
    "\n",
    "            n1 = np.asarray(utils.dec2bin_np_embed(i1, n_bit_input_number), dtype=np.float)\n",
    "            n2 = np.asarray(utils.dec2bin_np_embed(i2, n_bit_input_number), dtype=np.float)\n",
    "            input_test = np.concatenate((n1, n2), axis=1)\n",
    "    \n",
    "            [predictions_value, h1_value] = sess.run(\n",
    "                [predictions, h1],\n",
    "                feed_dict={inputs:input_test})\n",
    "        \n",
    "            result_dict['n1'] = n1\n",
    "            result_dict['n2'] = n2\n",
    "            result_dict['h1'] = h1_value\n",
    "            result_dict['output'] = predictions_value\n",
    "            \n",
    "            layers.append(result_dict)\n",
    "            \n",
    "            if len(layers) % 1000 == 0:\n",
    "                print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_to_save = 'data/add/layers/{}'.format(model_id)\n",
    "create_dir(dir_to_save)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(dir_to_save + '/layers.pickle', 'wb') as f: \n",
    "    pickle.dump(layers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Compute the variance of activations for each digit-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_to_import = 'data/add/layers/{}'.format(model_id)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(dir_to_import + '/layers.pickle', 'rb') as f: \n",
    "    layers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invariance_hidden_unit(layers, position, n1_digit, n2_digit):\n",
    "    h1_list = list()\n",
    "    for i in range(len(layers)):\n",
    "        n1 = layers[i]['n1']\n",
    "        n2 = layers[i]['n2']\n",
    "        h1 = layers[i]['h1']\n",
    "        # layers[i]['output']\n",
    "        if (n1[0,-position-1], n2[0,-position-1]) == (n1_digit, n2_digit):\n",
    "            h1_list.append(h1)\n",
    "\n",
    "    h1_set = np.zeros((len(h1_list), h1_list[0].shape[1]))\n",
    "    for i in range(len(h1_list)):\n",
    "        h1_set[i, :] = h1_list[i]\n",
    "\n",
    "    h1_var = np.var(h1_set, axis=0)\n",
    "    return (np.min(h1_var), np.max(h1_var), np.argmin(h1_var), np.argmax(h1_var), np.argsort(h1_var), np.sort(h1_var), np.mean(h1_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_hidden_unit(layers, position, n1_digit, n2_digit):\n",
    "    h1_list = list()\n",
    "    for i in range(len(layers)):\n",
    "        n1 = layers[i]['n1']\n",
    "        n2 = layers[i]['n2']\n",
    "        h1 = layers[i]['h1']\n",
    "        # layers[i]['output']\n",
    "        if (n1[0,position], n2[0,position]) == (n1_digit, n2_digit):\n",
    "            h1_list.append(h1)\n",
    "\n",
    "    h1_set = np.zeros((len(h1_list), h1_list[0].shape[1]))\n",
    "    for i in range(len(h1_list)):\n",
    "        h1_set[i, :] = h1_list[i]\n",
    "\n",
    "    h1_mean = np.mean(h1_set, axis=0)\n",
    "    return np.sort(h1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_invariance_hidden_unit(layers, 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_invariance_hidden_unit(layers, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_digit_input_number = layers[0]['n1'].shape[1]\n",
    "for i in range(n_digit_input_number):\n",
    "    position = i\n",
    "    print(\"position={}\".format(position))\n",
    "    print(get_invariance_hidden_unit(layers, position, 0, 0)[4])\n",
    "    print(get_invariance_hidden_unit(layers, position, 1, 0)[4])\n",
    "    print(get_invariance_hidden_unit(layers, position, 0, 1)[4])\n",
    "    print(get_invariance_hidden_unit(layers, position, 1, 1)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_invariance_hidden_unit(layers, 1, 0, 0)[4])\n",
    "print(get_invariance_hidden_unit(layers, 0, 1, 0)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(np.absolute(get_mean_hidden_unit(layers, 1, 0, 0) - get_mean_hidden_unit(layers, 0, 1, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 16, 17, 18th units in the hidden layer seem to operate addition of 0 and 1 in the 1st position.\n",
    "\n",
    "That's because the units have small variance and their mean is small difference among the inputs that give out the same output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
