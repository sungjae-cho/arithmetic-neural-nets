{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle carry datasets\n",
    "\n",
    "* `carry_datasets` is the ordered dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_datasets = import_carry_datasets(4, 'add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for carries in carry_datasets.keys():\n",
    "    carry_ds_size = carry_datasets[carries]['input'].shape[0]\n",
    "    randomize = np.arange(carry_ds_size)\n",
    "    np.random.shuffle(randomize)\n",
    "    carry_datasets[carries]['input'] = carry_datasets[carries]['input'][randomize]\n",
    "    carry_datasets[carries]['output'] = carry_datasets[carries]['output'][randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carry_datasets[0]['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carry_datasets[0]['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_carry_datasets(carry_datasets):\n",
    "    for carries in carry_datasets.keys():\n",
    "        carry_ds_size = carry_datasets[carries]['input'].shape[0]\n",
    "        randomize = np.arange(carry_ds_size)\n",
    "        np.random.shuffle(randomize)\n",
    "        carry_datasets[carries]['input'] = carry_datasets[carries]['input'][randomize]\n",
    "        carry_datasets[carries]['output'] = carry_datasets[carries]['output'][randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_carry_datasets(carry_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carry_datasets[0]['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carry_datasets[0]['output'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add codes to write shuffled carry_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_carry_datasets(carry_datasets, operand_digits, operator):\n",
    "    save_dir = 'data/{}-bit/{}'.format(operand_digits, operator)\n",
    "    create_dir(save_dir)\n",
    "\n",
    "    # Ordered carry datasets\n",
    "    save_path = '{}/carry_datasets.pickle'.format(save_dir)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(carry_datasets, f)\n",
    "    print(\"Saved in '{}'.\".format(save_path))\n",
    "\n",
    "    # Ordered carry datasets\n",
    "    shuffle_carry_datasets(carry_datasets)\n",
    "    save_path = '{}/shuffled_carry_datasets.pickle'.format(save_dir)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(carry_datasets, f)\n",
    "    print(\"Saved in '{}'.\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `k*l`-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_input = np.arange(256*3).reshape((256,3))\n",
    "np_target = np.arange(256*3).reshape((256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KL_fold_CV_sets(np_input, np_target, i_iteration, n_outer_folds=5, n_inner_folds=5):\n",
    "    '''\n",
    "    np_input : numpy.ndarray. shape=(n_examples, dim_input).\n",
    "    np_target : numpy.ndarray. shape=(n_examples, dim_target).\n",
    "    i_iteration : The iteration index of cross validation.\n",
    "     - i_iteration should range from 0 to (n_outer_folds * n_inner_folds - 1)\n",
    "    '''\n",
    "    if (i_iteration < 0) or (i_iteration >= n_outer_folds * n_inner_folds):\n",
    "        raise ValueError(\"i_iteration should range from 0 to (n_outer_folds * n_inner_folds - 1)\")\n",
    "    \n",
    "    # Get the indices of outer folds and inner folds.\n",
    "    i_outer_fold = i_iteration // n_outer_folds\n",
    "    i_inner_fold = i_iteration % n_outer_folds\n",
    "    \n",
    "    ds_size = np_input.shape[0]\n",
    "    outer_fold_size = ds_size // n_outer_folds\n",
    "    inner_fold_size = (ds_size - outer_fold_size) // n_inner_folds\n",
    "    \n",
    "    # Get the start and end indices of the test set.\n",
    "    i_start_test = i_outer_fold * outer_fold_size\n",
    "    if i_outer_fold < n_outer_folds - 1:\n",
    "        i_end_test = (i_outer_fold + 1) * outer_fold_size\n",
    "    else:\n",
    "        # Without this flow control, the remainders are never included in the test set.\n",
    "        i_end_test = ds_size\n",
    "        \n",
    "    # Get the test set.\n",
    "    input_test = np_input[i_start_test:i_end_test,:]\n",
    "    target_test = np_target[i_start_test:i_end_test,:]\n",
    "    \n",
    "    # Get the inner dataset\n",
    "    inner_input_dataset = np.concatenate((np_input[:i_start_test,:], np_input[i_end_test:,:]), axis=0)\n",
    "    inner_target_dataset = np.concatenate((np_target[:i_start_test,:], np_target[i_end_test:,:]), axis=0)\n",
    "    \n",
    "    # Get the inner fold size\n",
    "    inner_ds_size = inner_input_dataset.shape[0]\n",
    "    inner_fold_size = inner_ds_size // n_inner_folds\n",
    "    \n",
    "    # Get the start and end indices of the dev set.\n",
    "    i_start_dev = i_inner_fold * inner_fold_size\n",
    "    i_end_dev = (i_inner_fold + 1) * inner_fold_size\n",
    "    \n",
    "    # Get the dev set.\n",
    "    input_dev = inner_input_dataset[i_start_dev:i_end_dev,:]\n",
    "    target_dev = inner_target_dataset[i_start_dev:i_end_dev,:]\n",
    "    \n",
    "    # Get the train set.\n",
    "    input_train = np.concatenate((inner_input_dataset[:i_start_dev,:], inner_input_dataset[i_end_dev:,:]), axis=0)\n",
    "    target_train = np.concatenate((inner_target_dataset[:i_start_dev,:], inner_target_dataset[i_end_dev:,:]), axis=0)\n",
    "    \n",
    "    return (input_train, input_dev, input_test,\n",
    "            target_train, target_dev, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final correctness: True\n"
     ]
    }
   ],
   "source": [
    "n_outer_folds = 5\n",
    "n_inner_folds = 5\n",
    "correctness = True\n",
    "n_cv_iterations = n_outer_folds * n_inner_folds\n",
    "for i_iteration in range(n_cv_iterations):\n",
    "    (input_train, input_dev, input_test,\n",
    "     target_train, target_dev, target_test) = get_KL_fold_CV_sets(np_input, np_target, i_iteration, n_outer_folds, n_inner_folds)\n",
    "    correctness = correctness and (np_input.shape[0] == input_train.shape[0] + input_dev.shape[0] + input_test.shape[0])\n",
    "    correctness = correctness and (np_target.shape[0] == target_train.shape[0] + target_dev.shape[0] + target_test.shape[0])\n",
    "print(\"Final correctness: {}\".format(correctness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final correctness: True\n"
     ]
    }
   ],
   "source": [
    "n_outer_folds = 10\n",
    "n_inner_folds = 10\n",
    "correctness = True\n",
    "n_cv_iterations = n_outer_folds * n_inner_folds\n",
    "for i_iteration in range(n_cv_iterations):\n",
    "    (input_train, input_dev, input_test,\n",
    "     target_train, target_dev, target_test) = get_KL_fold_CV_sets(np_input, np_target, i_iteration, n_outer_folds, n_inner_folds)\n",
    "    correctness = correctness and (np_input.shape[0] == input_train.shape[0] + input_dev.shape[0] + input_test.shape[0])\n",
    "    correctness = correctness and (np_target.shape[0] == target_train.shape[0] + target_dev.shape[0] + target_test.shape[0])\n",
    "print(\"Final correctness: {}\".format(correctness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `k*l`-fold cross validation: with carry datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_datasets = import_carry_datasets(4, 'add', shuffled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_list = list()\n",
    "target_train_list = list()\n",
    "input_dev_list = list()\n",
    "target_dev_list = list()\n",
    "input_test_list = list()\n",
    "target_test_list = list()\n",
    "\n",
    "i_iteration = 0\n",
    "\n",
    "for carries in carry_datasets.keys():\n",
    "    np_input = carry_datasets[carries]['input']\n",
    "    np_target = carry_datasets[carries]['output']\n",
    "    \n",
    "    (input_train, input_dev, input_test,\n",
    "     target_train, target_dev, target_test) = get_KL_fold_CV_sets(np_input, np_target, i_iteration, n_outer_folds=5, n_inner_folds=5)\n",
    "    \n",
    "    input_train_list.append(input_train)\n",
    "    target_train_list.append(target_train)\n",
    "    input_dev_list.append(input_dev)\n",
    "    target_dev_list.append(target_dev)\n",
    "    input_test_list.append(input_test)\n",
    "    target_test_list.append(target_test)\n",
    "    \n",
    "input_train = np.concatenate(input_train_list, axis=0)\n",
    "target_train = np.concatenate(target_train_list, axis=0)\n",
    "input_dev = np.concatenate(input_dev_list, axis=0)\n",
    "target_dev = np.concatenate(target_dev_list, axis=0)\n",
    "input_test = np.concatenate(input_test_list, axis=0)\n",
    "target_test = np.concatenate(target_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 8)\n",
      "(168, 8)\n",
      "(39, 8)\n",
      "(39, 8)\n",
      "(49, 8)\n",
      "(49, 8)\n"
     ]
    }
   ],
   "source": [
    "print(input_train.shape)\n",
    "print(target_train.shape)\n",
    "print(input_dev.shape)\n",
    "print(target_dev.shape)\n",
    "print(input_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape[0] + input_dev.shape[0] + input_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape[0] + target_dev.shape[0] + target_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[0], target_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dev[0], target_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 0, 1, 0, 1]), array([0, 0, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test[0], target_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KL_fold_CV_sets_from_carry_datasets(operand_digits, operator, i_iteration, n_outer_folds=5, n_inner_folds=5):\n",
    "    '''\n",
    "    Parameters\n",
    "    -----\n",
    "    operand_digits : int. The number of each operand digits.\n",
    "    operator : str. One of 'add', 'subtract', 'multiply', 'divide', 'modulo'\n",
    "    i_iteration : The iteration index of cross validation.\n",
    "     - i_iteration should range from 0 to (n_outer_folds * n_inner_folds - 1)\n",
    "    n_outer_folds : int. The number of outer folds.\n",
    "    n_inner_folds : int. The number of inner folds.\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "    (input_train, input_dev, input_test, target_train, target_dev, target_test) :\n",
    "     - For each element, numpy.ndarray. shape=(n_examples, dim).\n",
    "    splited_carry_datasets : dict.\n",
    "     - {n_carries:\n",
    "            {'input': {'train': numpy.ndarray,\n",
    "                        'dev': numpy.ndarray,\n",
    "                        'test': numpy.ndarray},\n",
    "            'output': {'train': numpy.ndarray,\n",
    "                        'dev': numpy.ndarray,\n",
    "                        'test': numpy.ndarray}, ...\n",
    "            }\n",
    "        }\n",
    "     -\n",
    "    '''\n",
    "    carry_datasets = import_carry_datasets(operand_digits, operator, shuffled=True)\n",
    "\n",
    "    input_train_list = list()\n",
    "    target_train_list = list()\n",
    "    input_dev_list = list()\n",
    "    target_dev_list = list()\n",
    "    input_test_list = list()\n",
    "    target_test_list = list()\n",
    "\n",
    "    splited_carry_datasets = dict()\n",
    "\n",
    "    for carries in carry_datasets.keys():\n",
    "        np_input = carry_datasets[carries]['input']\n",
    "        np_target = carry_datasets[carries]['output']\n",
    "\n",
    "        (input_train, input_dev, input_test,\n",
    "         target_train, target_dev, target_test) = get_KL_fold_CV_sets(np_input, np_target, i_iteration, n_outer_folds, n_inner_folds)\n",
    "\n",
    "        input_train_list.append(input_train)\n",
    "        target_train_list.append(target_train)\n",
    "        input_dev_list.append(input_dev)\n",
    "        target_dev_list.append(target_dev)\n",
    "        input_test_list.append(input_test)\n",
    "        target_test_list.append(target_test)\n",
    "\n",
    "        # Initialize a dict for the number of carries\n",
    "        splited_carry_datasets[carries] = dict()\n",
    "        splited_carry_datasets[carries]['input'] = dict()\n",
    "        splited_carry_datasets[carries]['output'] = dict()\n",
    "\n",
    "        splited_carry_datasets[carries]['input']['train'] = input_train\n",
    "        splited_carry_datasets[carries]['output']['train'] = target_train\n",
    "        splited_carry_datasets[carries]['input']['dev'] = input_dev\n",
    "        splited_carry_datasets[carries]['output']['dev'] = target_dev\n",
    "        splited_carry_datasets[carries]['input']['test'] = input_test\n",
    "        splited_carry_datasets[carries]['output']['test'] = target_test\n",
    "\n",
    "    input_train = np.concatenate(input_train_list, axis=0)\n",
    "    target_train = np.concatenate(target_train_list, axis=0)\n",
    "    input_dev = np.concatenate(input_dev_list, axis=0)\n",
    "    target_dev = np.concatenate(target_dev_list, axis=0)\n",
    "    input_test = np.concatenate(input_test_list, axis=0)\n",
    "    target_test = np.concatenate(target_test_list, axis=0)\n",
    "\n",
    "    return (input_train, input_dev, input_test,\n",
    "            target_train, target_dev, target_test, \n",
    "            splited_carry_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_train, input_dev, input_test, target_train, target_dev, target_test, splited_carry_datasets) = get_KL_fold_CV_sets_from_carry_datasets(4, 'add', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape[0] + input_dev.shape[0] + input_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape[0] + target_dev.shape[0] + target_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[0], target_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dev[0], target_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 0, 1, 0, 1]), array([0, 0, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test[0], target_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 8) (13, 8) (16, 8)\n",
      "(36, 8) (8, 8) (10, 8)\n",
      "(34, 8) (8, 8) (10, 8)\n",
      "(28, 8) (6, 8) (8, 8)\n",
      "(18, 8) (4, 8) (5, 8)\n"
     ]
    }
   ],
   "source": [
    "for carries in splited_carry_datasets.keys():\n",
    "    print(splited_carry_datasets[carries]['input']['train'].shape, splited_carry_datasets[carries]['input']['dev'].shape, splited_carry_datasets[carries]['input']['test'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
